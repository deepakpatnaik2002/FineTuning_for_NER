{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeUx6_9_NS_W"
   },
   "source": [
    "# Question-2 : Fine-tuning IndicBERT and IndicNER for telugu language using 5%(25,870 files) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usS9PGGbNPlY"
   },
   "source": [
    "## Installing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-12T19:06:28.481026Z",
     "iopub.status.busy": "2024-03-12T19:06:28.479751Z",
     "iopub.status.idle": "2024-03-12T19:07:23.971348Z",
     "shell.execute_reply": "2024-03-12T19:07:23.970229Z",
     "shell.execute_reply.started": "2024-03-12T19:06:28.480981Z"
    },
    "id": "i89zZVJpQzGy",
    "outputId": "8ee1e816-846d-46dc-ddcb-651b706f3c7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (1.26.1)\n",
      "Collecting pyarrow>=12.0.0 (from datasets)\n",
      "  Downloading pyarrow-15.0.1-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (4.66.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.3-cp310-cp310-win_amd64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-win_amd64.whl.metadata (32 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (3.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "   ---------------------------------------- 510.5/510.5 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "   ---------------------------------------- 116.3/116.3 kB 7.1 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.3-cp310-cp310-win_amd64.whl (365 kB)\n",
      "   ---------------------------------------- 365.2/365.2 kB 7.6 MB/s eta 0:00:00\n",
      "Downloading pyarrow-15.0.1-cp310-cp310-win_amd64.whl (24.8 MB)\n",
      "   ---------------------------------------- 24.8/24.8 MB 2.0 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "   ---------------------------------------- 134.8/134.8 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 60.8/60.8 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 50.4/50.4 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Downloading yarl-1.9.4-cp310-cp310-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 76.4/76.4 kB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, frozenlist, dill, attrs, async-timeout, yarl, multiprocess, aiosignal, aiohttp, datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.2.0 datasets-2.18.0 dill-0.3.8 frozenlist-1.4.1 multidict-6.0.5 multiprocess-0.70.16 pyarrow-15.0.1 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers\n",
    "!pip3 install datasets\n",
    "!pip3 install sentencepiece\n",
    "!pip3 install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-12T19:07:23.973775Z",
     "iopub.status.busy": "2024-03-12T19:07:23.973408Z",
     "iopub.status.idle": "2024-03-12T19:07:37.590803Z",
     "shell.execute_reply": "2024-03-12T19:07:37.589601Z",
     "shell.execute_reply.started": "2024-03-12T19:07:23.973738Z"
    },
    "id": "O0_iT27XNcmA",
    "outputId": "46affeda-05b6-42b7-ead9-43f4e81b96f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.27.2)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.27.2\n",
      "    Uninstalling accelerate-0.27.2:\n",
      "      Successfully uninstalled accelerate-0.27.2\n",
      "Successfully installed accelerate-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U\n",
    "#NOTE: AFTER RUNNING THIS CELL,MAKESURE TO RESTART KERNEL RUNTIME AND THEN DONOT RERUN ANY CELLS WITH !pip install IN THEM,TO AVOID ERROR OCCURED WHILE EXECUTING args training arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F48-tLybQ3va"
   },
   "source": [
    "# Question-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9SRN_CeTJX0"
   },
   "source": [
    "# Step-1: Downloading the Namapadam dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:07:41.371024Z",
     "iopub.status.busy": "2024-03-12T19:07:41.370011Z",
     "iopub.status.idle": "2024-03-12T19:08:48.245207Z",
     "shell.execute_reply": "2024-03-12T19:08:48.244313Z",
     "shell.execute_reply.started": "2024-03-12T19:07:41.370979Z"
    },
    "id": "kz6cFoTYQ6y3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48523fae5524771aa55661e7ae82995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset naamapadam_pr/te to /root/.cache/huggingface/datasets/ai4bharat___naamapadam_pr/te/1.0.0/99b5ec77eabfaa3fbff510d8cf70d7c34519486cb7dbee99ede19474ddff9b20...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c5a9413e5846ae93a98aae47b414c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/25.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset naamapadam_pr downloaded and prepared to /root/.cache/huggingface/datasets/ai4bharat___naamapadam_pr/te/1.0.0/99b5ec77eabfaa3fbff510d8cf70d7c34519486cb7dbee99ede19474ddff9b20. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce38e22f1f0b452dbe9cea22dbf1049a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "lang='te'\n",
    "\n",
    "raw_datasets = load_dataset('ai4bharat/naamapadam', lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FJNvKjCWOVx"
   },
   "source": [
    "# Step-2: Analyzing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:08:48.247295Z",
     "iopub.status.busy": "2024-03-12T19:08:48.246837Z",
     "iopub.status.idle": "2024-03-12T19:08:48.253707Z",
     "shell.execute_reply": "2024-03-12T19:08:48.252921Z",
     "shell.execute_reply.started": "2024-03-12T19:08:48.247270Z"
    },
    "id": "Jn7mBxV4TjW-",
    "outputId": "61b917fd-7e28-49fe-e689-d4b96694756a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 507741\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 847\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 2700\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the dataset to see how it is\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:08:48.255194Z",
     "iopub.status.busy": "2024-03-12T19:08:48.254881Z",
     "iopub.status.idle": "2024-03-12T19:08:48.262159Z",
     "shell.execute_reply": "2024-03-12T19:08:48.261199Z",
     "shell.execute_reply.started": "2024-03-12T19:08:48.255153Z"
    },
    "id": "WUc-gpjNWW4b"
   },
   "outputs": [],
   "source": [
    "named_entity_features=raw_datasets[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:08:48.265011Z",
     "iopub.status.busy": "2024-03-12T19:08:48.264391Z",
     "iopub.status.idle": "2024-03-12T19:08:48.270579Z",
     "shell.execute_reply": "2024-03-12T19:08:48.269631Z",
     "shell.execute_reply.started": "2024-03-12T19:08:48.264968Z"
    },
    "id": "uK3Z4VbiU-ZY",
    "outputId": "5515ad77-0070-4413-cfb9-5fa68050947b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tokens', 'ner_tags']\n"
     ]
    }
   ],
   "source": [
    "column_names = raw_datasets[\"train\"].column_names\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:08:48.272518Z",
     "iopub.status.busy": "2024-03-12T19:08:48.271905Z",
     "iopub.status.idle": "2024-03-12T19:08:48.280974Z",
     "shell.execute_reply": "2024-03-12T19:08:48.280047Z",
     "shell.execute_reply.started": "2024-03-12T19:08:48.272485Z"
    },
    "id": "TzbxSg0sT8QX",
    "outputId": "dc73fddd-f74e-4618-9075-803e56976e2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word:రూ\tNamed Entity:0\n",
      "Word:.\tNamed Entity:0\n",
      "Word:50,000\tNamed Entity:0\n",
      "Word:డిస్కౌంట్\tNamed Entity:0\n"
     ]
    }
   ],
   "source": [
    "# printing 100th row from train dataset in given Namapadam corpus\n",
    "idx=100\n",
    "rec=raw_datasets['train'][idx]\n",
    "for w, t in zip(rec['tokens'],rec['ner_tags']):\n",
    "  print('Word:{}\\tNamed Entity:{}'.format(w,t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FKZrA59VeU1"
   },
   "source": [
    "The named entities are labelled as integers,so let's try to get the corresponding named entities for those integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:08:48.282874Z",
     "iopub.status.busy": "2024-03-12T19:08:48.282320Z",
     "iopub.status.idle": "2024-03-12T19:08:48.289831Z",
     "shell.execute_reply": "2024-03-12T19:08:48.288925Z",
     "shell.execute_reply.started": "2024-03-12T19:08:48.282841Z"
    },
    "id": "ntmtH96jUi5V",
    "outputId": "54a39626-cda3-4e7f-a0cd-ef3364397633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:O\t Integer Id:0\n",
      "label:B-PER\t Integer Id:1\n",
      "label:I-PER\t Integer Id:2\n",
      "label:B-ORG\t Integer Id:3\n",
      "label:I-ORG\t Integer Id:4\n",
      "label:B-LOC\t Integer Id:5\n",
      "label:I-LOC\t Integer Id:6\n",
      "{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n"
     ]
    }
   ],
   "source": [
    "labels_list = named_entity_features['ner_tags'].feature.names\n",
    "\n",
    "map_label_to_id={} # dictionary to store the mapping between label and its corresponding integer id\n",
    "for i in range(len(labels_list)):\n",
    "  map_label_to_id[labels_list[i]]=named_entity_features['ner_tags'].feature.str2int(labels_list[i])\n",
    "for label_id in map_label_to_id:\n",
    "  print('label:{}\\t Integer Id:{}'.format(label_id,map_label_to_id[label_id]))\n",
    "print(map_label_to_id)\n",
    "num_labels=len(labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTCmhAkJbRg5"
   },
   "source": [
    "# Step-3: Fine-tuning **IndicNER model** on the Naamapadam corpus for **TELUGU language**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:08:52.823023Z",
     "iopub.status.busy": "2024-03-12T19:08:52.822659Z",
     "iopub.status.idle": "2024-03-12T19:09:14.261320Z",
     "shell.execute_reply": "2024-03-12T19:09:14.260332Z",
     "shell.execute_reply.started": "2024-03-12T19:08:52.822993Z"
    },
    "id": "l6YmSOQ7a0vy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 19:09:01.252405: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-12 19:09:01.252507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-12 19:09:01.381491: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f43f8e94714661b8242b128339602e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/346 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5813c4c7de444c65b91f300ecfd1257b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f2e84d3f6a42898ae92b0ebf1502b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3574b1a2f97c4ce6803fb27c212700a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a366ac90bd5240d69da07cb8127d8c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d7c76626814c0aa92df7fad861379d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/667M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "#Loading the Pre-trained IndicNER model\n",
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicNER\")\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"ai4bharat/IndicNER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQfXP1bqhvvp"
   },
   "outputs": [],
   "source": [
    "# moving the model to Colab GPU\n",
    "model=model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:09:14.263488Z",
     "iopub.status.busy": "2024-03-12T19:09:14.262890Z",
     "iopub.status.idle": "2024-03-12T19:09:14.271772Z",
     "shell.execute_reply": "2024-03-12T19:09:14.270853Z",
     "shell.execute_reply.started": "2024-03-12T19:09:14.263461Z"
    },
    "id": "8YxRBTfvhgnK"
   },
   "outputs": [],
   "source": [
    "# tokenize the input text and aligns the labels with the corresponding tokens,tokenizer of IndicNER will only generate tokens specific to model,but this function will also assign NER to the tokens,which allows the model to learn the relationship between the input tokens and their corresponding entity labels during training.\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], #input tokens\n",
    "        padding=\"max_length\", #Pad the tokenized inputs to a maximum length specified with the argument max_length\n",
    "        truncation=True,#truncate the tokenized inputs if they exceed the maximum length\n",
    "        max_length=512,#maximum length of tokenized input\n",
    "        is_split_into_words=True,# We use this argument because the texts in our dataset are lists of words (with a label for each word).So,tokenizer should not further split the tokens into subwords or characters.\n",
    "    )\n",
    "    aligned_labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        # print(\"word_ids \",i,\" \",word_ids)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for curr_word_id in word_ids:#For each word ID, retrieve the corresponding NER tag from the labels\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically ignored in the loss function.\n",
    "            if curr_word_id is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.(checks if the current token is the first token of its corresponding word,as a single word may be split into multiple tokens while tokenizing text)\n",
    "            elif curr_word_id != previous_word_idx:\n",
    "                label_ids.append(label[curr_word_id])\n",
    "            # For the other tokens in a word(it's part of a word that has already been started by a previous token), we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.If label_all_tokens is True, then the label for the current token is assigned based on the label for that word. If it's False, then the label for non-first tokens is set to -100 to ignore them during training.\n",
    "            # but by default we set the label to -100 for non-first tokens.\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = curr_word_id\n",
    "\n",
    "        aligned_labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = aligned_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "c83f132f38e14d53a48e0210be55148d"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-03-12T19:09:31.399349Z",
     "iopub.status.busy": "2024-03-12T19:09:31.398450Z",
     "iopub.status.idle": "2024-03-12T19:09:39.589339Z",
     "shell.execute_reply": "2024-03-12T19:09:39.588300Z",
     "shell.execute_reply.started": "2024-03-12T19:09:31.399316Z"
    },
    "id": "aSLTzePlVyVr",
    "outputId": "8fbe0317-6928-4ffd-800a-177e8816522b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbb45d4031041a585428cc830a6051e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on 5% subset of train dataset #0:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7054dc29317f4f98be65513ebbb45822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on 5% subset of train dataset #1:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e98e3693794396b4d719ed20bda416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on 5% subset of train dataset #2:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c8fa1cf4b643fe98d0e5673e21f024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on 5% subset of train dataset #3:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = raw_datasets[\"train\"] # given train dataset\n",
    "# Shuffle the train dataset\n",
    "train_dataset = train_dataset.shuffle(seed=42)\n",
    "\n",
    "# Get the first 25% of the examples\n",
    "num_examples = len(train_dataset)\n",
    "subset_size = int(num_examples * 0.05)\n",
    "train_subset = train_dataset.select(range(subset_size))\n",
    "\n",
    "# Tokenize and align labels for the subset\n",
    "train_subset = train_subset.map(\n",
    "    tokenize_and_align_labels,  # Preprocess each example using the tokenize_and_align_labels function\n",
    "    batched=True,  # Use batch processing instead of individual processing\n",
    "    num_proc=4,  # Number of processes to use for parallel processing\n",
    "    load_from_cache_file=True,  # Load from cache file if available\n",
    "    desc=\"Running tokenizer on 5% subset of train dataset\",  # Description for the progress bar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:09:46.175415Z",
     "iopub.status.busy": "2024-03-12T19:09:46.175038Z",
     "iopub.status.idle": "2024-03-12T19:09:47.291220Z",
     "shell.execute_reply": "2024-03-12T19:09:47.290143Z",
     "shell.execute_reply.started": "2024-03-12T19:09:46.175384Z"
    },
    "id": "ggX7D3ZvvKQ5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e5b78acf9f4727b883cf02994a6c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on Validation dataset #0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5aa0121bde48eca4ca9adef07ffcce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on Validation dataset #1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cbfd222db74b8babfcaf6d746204af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on Validation dataset #2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa58c9bea5748ffb4eb48d5befd54af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on Validation dataset #3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset = raw_datasets[\"validation\"] #tokenizing and aligning the labels for the validation dataset\n",
    "eval_dataset = eval_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Running tokenizer on Validation dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:09:49.435236Z",
     "iopub.status.busy": "2024-03-12T19:09:49.434312Z",
     "iopub.status.idle": "2024-03-12T19:09:50.016030Z",
     "shell.execute_reply": "2024-03-12T19:09:50.015022Z",
     "shell.execute_reply.started": "2024-03-12T19:09:49.435192Z"
    },
    "id": "qK3RzGEUQtZm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce58f2f610c84ae8b9923800724e0af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on test dataset #0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5921b92f1446feaea87a8695ba453b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on test dataset #2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bed33f32f764ca39270ad21b20fc4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on test dataset #1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ec84f81a164767a2be87fc56528309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on test dataset #3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = raw_datasets[\"test\"]\n",
    "test_dataset = test_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Running tokenizer on test dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQAU_ID0ynPc"
   },
   "source": [
    "### Create collator,metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:09:54.807865Z",
     "iopub.status.busy": "2024-03-12T19:09:54.807508Z",
     "iopub.status.idle": "2024-03-12T19:09:54.812674Z",
     "shell.execute_reply": "2024-03-12T19:09:54.811477Z",
     "shell.execute_reply.started": "2024-03-12T19:09:54.807838Z"
    },
    "id": "Q5md7DiQxxz_"
   },
   "outputs": [],
   "source": [
    "#data_collator- used to take input data samples and organize them into batches suitable for efficient training of the machine learning model.\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:10:33.828603Z",
     "iopub.status.busy": "2024-03-12T19:10:33.827983Z",
     "iopub.status.idle": "2024-03-12T19:10:34.204825Z",
     "shell.execute_reply": "2024-03-12T19:10:34.203987Z",
     "shell.execute_reply.started": "2024-03-12T19:10:33.828564Z"
    },
    "id": "mcSLHkq9yX6x",
    "outputId": "f8ebb925-135f-412b-b8a0-2ce9559c12c7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca71eb819d847dc840bcb1de0051e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Metrics\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [labels_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [labels_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    # Unpack nested dictionaries\n",
    "    final_results = {}\n",
    "    for key, value in results.items():\n",
    "        if isinstance(value, dict):\n",
    "            for n, v in value.items():\n",
    "                final_results[f\"{key}_{n}\"] = v\n",
    "        else:\n",
    "            final_results[key] = value\n",
    "    try:\n",
    "        if results[\"overall_f1\"]:\n",
    "            final_results[\"f1\"] = results[\"overall_f1\"]\n",
    "    except KeyError:\n",
    "        pass  # If \"overall_f1\" is not present in results, do nothing\n",
    "    #if results[\"overall_f1\"]: final_results[\"f1\"]=results[\"overall_f1\"]\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1pj0bEVwXwh"
   },
   "source": [
    "## Set Training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:10:40.446701Z",
     "iopub.status.busy": "2024-03-12T19:10:40.446232Z",
     "iopub.status.idle": "2024-03-12T19:10:40.547455Z",
     "shell.execute_reply": "2024-03-12T19:10:40.546621Z",
     "shell.execute_reply.started": "2024-03-12T19:10:40.446670Z"
    },
    "id": "bpLyNfXtvKTD"
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='./checkpoints',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=3e-5,  # Set the learning rate\n",
    "    weight_decay=0.01,    # Set the weight decay\n",
    "    gradient_accumulation_steps=1,  # Number of updates steps to accumulate before performing a backward/update pass.\n",
    "    logging_dir='./logs',  # Directory for storing logs\n",
    "    logging_steps=10,   # Log every n updates steps\n",
    "    save_strategy=\"epoch\",  # Save model after each epoch\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate after each epoch\n",
    "    save_total_limit=1,  # Limit the total amount of saved models\n",
    "    label_smoothing_factor=0.1,  # Apply label smoothing for regularization\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:10:49.006289Z",
     "iopub.status.busy": "2024-03-12T19:10:49.005519Z",
     "iopub.status.idle": "2024-03-12T19:10:50.192335Z",
     "shell.execute_reply": "2024-03-12T19:10:50.191306Z",
     "shell.execute_reply.started": "2024-03-12T19:10:49.006258Z"
    },
    "id": "yCRAL9lRvKVW",
    "outputId": "0ecbbd8b-9c75-453c-d263-a2d080eb1134"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_subset,#Note: CHANGE TO \"train_subset\",IF WORKING UNDER SUBSET OF TRAINING DATA.FOR OVERALL TRAINING DATA,USE \"train_dataset\"\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    args=args,\n",
    "    # callbacks=[SaveCheckpointsCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9KUGCKVw5a9"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:19:12.266408Z",
     "iopub.status.busy": "2024-03-12T19:19:12.265891Z",
     "iopub.status.idle": "2024-03-12T20:34:37.738708Z",
     "shell.execute_reply": "2024-03-12T20:34:37.737695Z",
     "shell.execute_reply.started": "2024-03-12T19:19:12.266377Z"
    },
    "id": "m0BhS8_avKXN",
    "outputId": "5b8b6644-6d42-4b7b-8b9e-8bfb8888ba49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m319106410006\u001b[0m (\u001b[33mjai-sri-ram\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240312_191912-o2xef8n7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jai-sri-ram/your_project_name/runs/o2xef8n7' target=\"_blank\">dauntless-valley-1</a></strong> to <a href='https://wandb.ai/jai-sri-ram/your_project_name' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jai-sri-ram/your_project_name' target=\"_blank\">https://wandb.ai/jai-sri-ram/your_project_name</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jai-sri-ram/your_project_name/runs/o2xef8n7' target=\"_blank\">https://wandb.ai/jai-sri-ram/your_project_name/runs/o2xef8n7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4761' max='4761' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4761/4761 1:14:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Loc Precision</th>\n",
       "      <th>Loc Recall</th>\n",
       "      <th>Loc F1</th>\n",
       "      <th>Loc Number</th>\n",
       "      <th>Org Precision</th>\n",
       "      <th>Org Recall</th>\n",
       "      <th>Org F1</th>\n",
       "      <th>Org Number</th>\n",
       "      <th>Per Precision</th>\n",
       "      <th>Per Recall</th>\n",
       "      <th>Per F1</th>\n",
       "      <th>Per Number</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.623600</td>\n",
       "      <td>0.616233</td>\n",
       "      <td>0.746046</td>\n",
       "      <td>0.813218</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>1044</td>\n",
       "      <td>0.702857</td>\n",
       "      <td>0.711668</td>\n",
       "      <td>0.707235</td>\n",
       "      <td>1037</td>\n",
       "      <td>0.773612</td>\n",
       "      <td>0.792914</td>\n",
       "      <td>0.783144</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.748703</td>\n",
       "      <td>0.777479</td>\n",
       "      <td>0.762820</td>\n",
       "      <td>0.925824</td>\n",
       "      <td>0.762820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.542000</td>\n",
       "      <td>0.621402</td>\n",
       "      <td>0.761773</td>\n",
       "      <td>0.790230</td>\n",
       "      <td>0.775740</td>\n",
       "      <td>1044</td>\n",
       "      <td>0.680987</td>\n",
       "      <td>0.718419</td>\n",
       "      <td>0.699202</td>\n",
       "      <td>1037</td>\n",
       "      <td>0.780187</td>\n",
       "      <td>0.789920</td>\n",
       "      <td>0.785024</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.749643</td>\n",
       "      <td>0.771848</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.925933</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.552200</td>\n",
       "      <td>0.629297</td>\n",
       "      <td>0.764160</td>\n",
       "      <td>0.788314</td>\n",
       "      <td>0.776049</td>\n",
       "      <td>1044</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>0.712633</td>\n",
       "      <td>0.698818</td>\n",
       "      <td>1037</td>\n",
       "      <td>0.771955</td>\n",
       "      <td>0.793912</td>\n",
       "      <td>0.782780</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.747865</td>\n",
       "      <td>0.771848</td>\n",
       "      <td>0.759668</td>\n",
       "      <td>0.924851</td>\n",
       "      <td>0.759668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import wandb\n",
    "# Initialize wandb\n",
    "wandb.init(project=\"your_project_name\")\n",
    "\n",
    "# Set your API key\n",
    "wandb.login(key=\"009ac958cc59c78ab471adbb4d25b34b06a416ba\")\n",
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMay-q5Mek-h"
   },
   "source": [
    "Load the checkpoint if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxNa9euIejX2"
   },
   "outputs": [],
   "source": [
    "# from transformers import Trainer\n",
    "\n",
    "# # Load the trained model and its corresponding tokenizer\n",
    "# model_checkpoint = \"./checkpoints\"  # Path to the directory containing the checkpoints\n",
    "\n",
    "# trainer = Trainer.from_pretrained(\n",
    "#     model_checkpoint,\n",
    "#     args=args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=eval_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T20:34:54.678100Z",
     "iopub.status.busy": "2024-03-12T20:34:54.677715Z",
     "iopub.status.idle": "2024-03-12T20:34:54.687395Z",
     "shell.execute_reply": "2024-03-12T20:34:54.684186Z",
     "shell.execute_reply.started": "2024-03-12T20:34:54.678064Z"
    },
    "id": "AygKHCfJVyVv",
    "outputId": "9debeab7-daa4-46a1-86b9-4a93fd236db3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 4493.9032, 'train_samples_per_second': 16.948, 'train_steps_per_second': 1.059, 'total_flos': 1.9901521891316736e+16, 'train_loss': 0.5740792902170473, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T20:35:02.414082Z",
     "iopub.status.busy": "2024-03-12T20:35:02.413669Z",
     "iopub.status.idle": "2024-03-12T20:35:02.423092Z",
     "shell.execute_reply": "2024-03-12T20:35:02.421999Z",
     "shell.execute_reply.started": "2024-03-12T20:35:02.414052Z"
    },
    "id": "8q8z-mwCeViQ",
    "outputId": "8832d302-7771-4d49-cb14-966464bda1a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        3.0\n",
      "  total_flos               = 18534736GF\n",
      "  train_loss               =     0.5741\n",
      "  train_runtime            = 1:14:53.90\n",
      "  train_samples_per_second =     16.948\n",
      "  train_steps_per_second   =      1.059\n"
     ]
    }
   ],
   "source": [
    "trainer.log_metrics(\"train\", train_result.metrics)\n",
    "# print(metrics['overall_f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3Ap8gM9xIKt"
   },
   "source": [
    "## Evaluate the model using Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T20:35:12.604766Z",
     "iopub.status.busy": "2024-03-12T20:35:12.604066Z",
     "iopub.status.idle": "2024-03-12T20:36:13.707354Z",
     "shell.execute_reply": "2024-03-12T20:36:13.705626Z",
     "shell.execute_reply.started": "2024-03-12T20:35:12.604733Z"
    },
    "id": "FdCjkIKayqRU",
    "outputId": "9521fb30-c964-43a4-810a-c494147c3d94"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_LOC_f1             =      0.776\n",
      "  eval_LOC_number         =       1044\n",
      "  eval_LOC_precision      =     0.7642\n",
      "  eval_LOC_recall         =     0.7883\n",
      "  eval_ORG_f1             =     0.6988\n",
      "  eval_ORG_number         =       1037\n",
      "  eval_ORG_precision      =     0.6855\n",
      "  eval_ORG_recall         =     0.7126\n",
      "  eval_PER_f1             =     0.7828\n",
      "  eval_PER_number         =       2004\n",
      "  eval_PER_precision      =      0.772\n",
      "  eval_PER_recall         =     0.7939\n",
      "  eval_f1                 =     0.7597\n",
      "  eval_loss               =     0.6293\n",
      "  eval_overall_accuracy   =     0.9249\n",
      "  eval_overall_f1         =     0.7597\n",
      "  eval_overall_precision  =     0.7479\n",
      "  eval_overall_recall     =     0.7718\n",
      "  eval_runtime            = 0:01:01.07\n",
      "  eval_samples_per_second =     44.208\n",
      "  eval_steps_per_second   =      2.767\n",
      "0.7596675099385617\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "print(metrics['eval_overall_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T20:36:18.003881Z",
     "iopub.status.busy": "2024-03-12T20:36:18.003468Z",
     "iopub.status.idle": "2024-03-12T20:36:36.922070Z",
     "shell.execute_reply": "2024-03-12T20:36:36.920656Z",
     "shell.execute_reply.started": "2024-03-12T20:36:18.003849Z"
    },
    "id": "WJDGCQiG10mn",
    "outputId": "10d6f294-4ef7-4521-c2ed-53f9d6cc9cc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7806691449814127\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "predictions, labels, metrics = trainer.predict(test_dataset)\n",
    "print(metrics['test_overall_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T20:36:36.924298Z",
     "iopub.status.busy": "2024-03-12T20:36:36.923932Z",
     "iopub.status.idle": "2024-03-12T20:36:36.936781Z",
     "shell.execute_reply": "2024-03-12T20:36:36.935557Z",
     "shell.execute_reply.started": "2024-03-12T20:36:36.924268Z"
    },
    "id": "qxGCUt5iVyVx",
    "outputId": "1ea142f0-2716-4b66-dec5-88d8f1a270dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** test metrics *****\n",
      "  test_LOC_f1             =     0.8067\n",
      "  test_LOC_number         =        483\n",
      "  test_LOC_precision      =     0.8143\n",
      "  test_LOC_recall         =     0.7992\n",
      "  test_ORG_f1             =     0.6855\n",
      "  test_ORG_number         =        263\n",
      "  test_ORG_precision      =     0.6791\n",
      "  test_ORG_recall         =      0.692\n",
      "  test_PER_f1             =      0.802\n",
      "  test_PER_number         =        609\n",
      "  test_PER_precision      =     0.8128\n",
      "  test_PER_recall         =     0.7915\n",
      "  test_f1                 =     0.7807\n",
      "  test_loss               =     0.6037\n",
      "  test_overall_accuracy   =     0.9335\n",
      "  test_overall_f1         =     0.7807\n",
      "  test_overall_precision  =     0.7865\n",
      "  test_overall_recall     =     0.7749\n",
      "  test_runtime            = 0:00:18.90\n",
      "  test_samples_per_second =     44.813\n",
      "  test_steps_per_second   =      2.804\n"
     ]
    }
   ],
   "source": [
    "trainer.log_metrics(\"test\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T20:36:42.869750Z",
     "iopub.status.busy": "2024-03-12T20:36:42.869321Z",
     "iopub.status.idle": "2024-03-12T20:36:42.906324Z",
     "shell.execute_reply": "2024-03-12T20:36:42.904976Z",
     "shell.execute_reply.started": "2024-03-12T20:36:42.869717Z"
    },
    "id": "QhFkROc8hUY0",
    "outputId": "82476e28-7ab7-44b1-c0f3-0b1c3500e6c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Predictions: [[ 3.144738   -1.1663034   0.4242542  ... -0.91630787 -0.92136586\n",
      "  -0.64984226]\n",
      " [ 3.4709692  -0.78675556 -0.57731515 ... -0.74683326 -0.74461263\n",
      "  -0.46643263]\n",
      " [ 3.4469821  -0.5499245  -0.6034052  ... -0.94339436 -0.7769071\n",
      "  -0.49291182]\n",
      " ...\n",
      " [ 0.36265033  0.13803276  3.2125306  ... -1.055425   -0.98815835\n",
      "  -1.0242915 ]\n",
      " [-0.03021973  1.5678442   2.2369585  ... -1.1946025  -0.9437661\n",
      "  -1.1882372 ]\n",
      " [-0.43924025  3.0054045   0.60141855 ... -1.0742683  -0.7082784\n",
      "  -1.2209603 ]]\n",
      "Labels: [-100    0    0 -100 -100 -100    0 -100 -100 -100 -100    1 -100 -100\n",
      "    2 -100 -100 -100    2 -100    0    0 -100 -100 -100 -100 -100    0\n",
      "    0    0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100]\n",
      "\n",
      "Example 2:\n",
      "Predictions: [[ 3.3916414  -0.5718747  -0.8340186  ... -0.8255898  -0.7226676\n",
      "  -0.6558075 ]\n",
      " [ 3.5994246  -0.682461   -0.7033458  ... -0.5982834  -0.69356054\n",
      "  -0.7377101 ]\n",
      " [ 3.588398   -0.68264997 -0.6360265  ... -0.7659404  -0.62632245\n",
      "  -0.7384256 ]\n",
      " ...\n",
      " [ 3.5510383  -0.6447631  -0.80120164 ... -0.75702536 -0.46266145\n",
      "  -0.7532557 ]\n",
      " [ 3.5492854  -0.62355995 -0.8822208  ... -0.8142961   0.11975634\n",
      "  -0.9301292 ]\n",
      " [ 2.7359326  -0.76165426 -1.0850224  ... -0.9283696   1.5700722\n",
      "  -1.0896173 ]]\n",
      "Labels: [-100    0 -100    5 -100 -100    0 -100    0 -100    0 -100 -100    0\n",
      " -100 -100    0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100]\n",
      "\n",
      "Example 3:\n",
      "Predictions: [[ 3.4306445  -0.7597192  -0.3218857  ... -0.82155234 -0.95245904\n",
      "  -0.7926322 ]\n",
      " [ 0.5871501  -0.83165216 -1.1130166  ... -0.9864481   3.278513\n",
      "  -1.1234847 ]\n",
      " [ 2.3173325  -0.7221221  -0.91440177 ... -0.55965585  1.3122047\n",
      "  -1.1496496 ]\n",
      " ...\n",
      " [ 1.9584484   0.2004683   0.8824712  ... -0.40222612 -1.0208309\n",
      "  -1.2518268 ]\n",
      " [ 3.4445367  -0.59569603 -0.6413523  ... -0.6476258  -0.5048886\n",
      "  -0.9064166 ]\n",
      " [ 2.2892826  -0.4409343  -1.1918237  ... -0.3344679   0.25876284\n",
      "  -1.2491844 ]]\n",
      "Labels: [-100    5 -100    0 -100 -100 -100 -100    0 -100 -100    0 -100 -100\n",
      "    1 -100 -100 -100    2 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100]\n",
      "\n",
      "Example 4:\n",
      "Predictions: [[ 3.4270067  -0.63051325 -0.44650722 ... -0.7282232  -0.9328915\n",
      "  -0.8702148 ]\n",
      " [ 0.43109927 -1.0511091  -0.97312427 ... -0.8819616   3.7067976\n",
      "  -1.1921724 ]\n",
      " [ 0.65299404 -0.72822386 -1.2409472  ... -0.9450692   3.3430285\n",
      "  -1.0962197 ]\n",
      " ...\n",
      " [ 2.7534788  -0.31768644 -1.4002383  ... -1.1935074   1.5145862\n",
      "  -0.881438  ]\n",
      " [ 3.543405   -0.47671232 -0.8037745  ... -0.82953227 -0.18719506\n",
      "  -0.8547535 ]\n",
      " [ 2.7591884  -0.42734984 -1.418478   ... -1.1783493   1.5243847\n",
      "  -0.81736386]]\n",
      "Labels: [-100    5 -100    0 -100 -100 -100 -100    1 -100 -100    2 -100 -100\n",
      "    5 -100    0 -100 -100 -100 -100 -100    0 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100]\n",
      "\n",
      "Example 5:\n",
      "Predictions: [[ 3.2665372  -0.9655794  -0.4842618  ... -0.6471704  -0.7743372\n",
      "  -0.7686385 ]\n",
      " [ 0.8540491   0.2721824  -1.569646   ... -0.7814199  -1.0394609\n",
      "  -1.0959883 ]\n",
      " [ 2.0152338  -0.8115025  -0.6894435  ... -0.10072777 -0.9989886\n",
      "  -1.2713163 ]\n",
      " ...\n",
      " [ 1.6130056   0.24167559 -1.439455   ... -0.8563633  -0.37344846\n",
      "  -1.1952143 ]\n",
      " [ 2.3519444  -0.31061023 -1.2027168  ... -0.69609964 -0.682709\n",
      "  -1.1769097 ]\n",
      " [ 1.7460036  -0.06232199 -1.3784672  ... -0.7372638  -0.29994997\n",
      "  -1.2464851 ]]\n",
      "Labels: [-100    0 -100 -100    0 -100 -100 -100    0    0 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_examples = 5\n",
    "for i in range(num_examples):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(\"Predictions:\", predictions[i])\n",
    "    print(\"Labels:\", labels[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Nh4SlN4XRMF"
   },
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T20:36:52.944788Z",
     "iopub.status.busy": "2024-03-12T20:36:52.944416Z",
     "iopub.status.idle": "2024-03-12T20:36:54.511802Z",
     "shell.execute_reply": "2024-03-12T20:36:54.510588Z",
     "shell.execute_reply.started": "2024-03-12T20:36:52.944762Z"
    },
    "id": "5MAB0lEweKG6"
   },
   "outputs": [],
   "source": [
    "trainer.save_model('CustomModel_NER')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4587482,
     "sourceId": 7828167,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
