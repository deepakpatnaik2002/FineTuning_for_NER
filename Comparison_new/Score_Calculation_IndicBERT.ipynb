{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2dnzT2SiPIM"
      },
      "source": [
        "## Question-4: Testing on Manually annotated dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-12T20:48:31.269496Z",
          "iopub.status.busy": "2024-03-12T20:48:31.268654Z",
          "iopub.status.idle": "2024-03-12T20:48:31.719138Z",
          "shell.execute_reply": "2024-03-12T20:48:31.717999Z",
          "shell.execute_reply.started": "2024-03-12T20:48:31.269464Z"
        },
        "id": "HCarf7Y9d7JA"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification,AutoTokenizer\n",
        "\n",
        "# Load the fine-tuned model\n",
        "model = AutoModelForTokenClassification.from_pretrained('IndicBERT_model')\n",
        "\n",
        "tokenizer=AutoTokenizer.from_pretrained('IndicBERT_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-12T20:38:28.979693Z",
          "iopub.status.busy": "2024-03-12T20:38:28.978947Z",
          "iopub.status.idle": "2024-03-12T20:38:28.989952Z",
          "shell.execute_reply": "2024-03-12T20:38:28.988718Z",
          "shell.execute_reply.started": "2024-03-12T20:38:28.979658Z"
        },
        "id": "5e7ap5jsdEYT",
        "outputId": "5850a887-9a75-4681-975b-b155e86a7914"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 32858375\n"
          ]
        }
      ],
      "source": [
        "# Get the number of trainable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "num_parameters = count_parameters(model)\n",
        "print(\"Number of trainable parameters:\", num_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-12T20:50:03.912925Z",
          "iopub.status.busy": "2024-03-12T20:50:03.912212Z",
          "iopub.status.idle": "2024-03-12T20:50:03.922617Z",
          "shell.execute_reply": "2024-03-12T20:50:03.921406Z",
          "shell.execute_reply.started": "2024-03-12T20:50:03.912892Z"
        },
        "id": "f8N9b2_ciONA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "def get_predictions( sentence, tokenizer, model ):\n",
        "  # Let us first tokenize the sentence - split words into subwords\n",
        "  tok_sentence = tokenizer(sentence, return_tensors='pt')\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # we will send the tokenized sentence to the model to get predictions\n",
        "    logits = model(**tok_sentence).logits.argmax(-1)\n",
        "\n",
        "    # We will map the maximum predicted class id with the class label\n",
        "    predicted_tokens_classes = [model.config.id2label[t.item()] for t in logits[0]]\n",
        "\n",
        "    predicted_labels = []\n",
        "\n",
        "    previous_token_id = 0\n",
        "    # we need to assign the named entity label to the head word and not the following sub-words\n",
        "    word_ids = tok_sentence.word_ids()\n",
        "    for word_index in range(len(word_ids)):\n",
        "        if word_ids[word_index] == None:\n",
        "            previous_token_id = word_ids[word_index]\n",
        "        elif word_ids[word_index] == previous_token_id:\n",
        "            previous_token_id = word_ids[word_index]\n",
        "        else:\n",
        "            predicted_labels.append( predicted_tokens_classes[ word_index ] )\n",
        "            previous_token_id = word_ids[word_index]\n",
        "\n",
        "    return predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-12T20:51:22.092964Z",
          "iopub.status.busy": "2024-03-12T20:51:22.092267Z",
          "iopub.status.idle": "2024-03-12T20:51:22.100709Z",
          "shell.execute_reply": "2024-03-12T20:51:22.099403Z",
          "shell.execute_reply.started": "2024-03-12T20:51:22.092929Z"
        },
        "id": "SLBsMzio-dLg"
      },
      "outputs": [],
      "source": [
        "# Open the text file in read mode\n",
        "with open('25 Sentences.txt', 'r') as file:\n",
        "  sentences=file.read().split('$')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orAJAV1Gjspg",
        "outputId": "f978f06a-68ca-45e9-cb36-3e14e6667c8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "నా\tO\n",
            "ప్రయాణం\tO\n",
            "మొత్తం\tO\n",
            "పదిరోజులే\tO\n",
            "కాబట్టి\tO\n",
            "నేను\tO\n",
            "మూడు\tO\n",
            "నాలుగు\tO\n",
            "ప్రదేశాల\tO\n",
            "కన్న\tO\n",
            "ఎన్నుకోలేను\tO\n",
            ",\tO\n",
            "ఒక్కో\tO\n",
            "చోటా\tO\n",
            "రెండు\tO\n",
            "మూడు\tO\n",
            "రోజుల\tO\n",
            "కన్న\tO\n",
            "ఎక్కువ\tO\n",
            "సమయం\tO\n",
            "ఉండలేను\tO\n",
            ".\tO\n",
            "ప్రజల\tO\n",
            "మనోభావాలు\tO\n",
            ",\tO\n",
            "ఎమోషన్స్\tO\n",
            "కి\tO\n",
            "అంతగా\tO\n",
            "ప్రాముఖ్యత\tO\n",
            "ఇవ్వకుండా\tO\n",
            "తానుఅనుకున్న\tO\n",
            "పనులు\tO\n",
            "చక్కబెట్టేవారు\tO\n",
            ".\tO\n",
            "మద్యం\tO\n",
            "లేదా\tO\n",
            "సాధ్యం\tO\n",
            "కిరోసిన్\tO\n",
            "ఉపయోగించడం\tO\n",
            "ద్వారా\tO\n",
            "మరింత\tO\n",
            "సమర్ధవంతంగా\tO\n",
            "జరిమానా\tB-LOC\n",
            "నష్టం\tO\n",
            "తొలగించడానికి\tO\n",
            ".\tO\n",
            "మరో\tO\n",
            "వివాహం\tO\n",
            "చేసుకునేందుకు\tO\n",
            "వీలుగా\tO\n",
            "భార్య\tO\n",
            "పాయల్‌\tO\n",
            "నుంచి\tO\n",
            "విడాకులు\tO\n",
            "ఇప్పించాలి\tO\n",
            "'\tO\n",
            "అని\tO\n",
            "ఒమర్\tB-PER\n",
            "పిటిషన్‌లో\tO\n",
            "విన్నవించారు\tO\n",
            ".\tO\n",
            "అన్ని\tO\n",
            "ఇతర\tO\n",
            "ఈస్ట్\tO\n",
            "వంటి\tO\n",
            ",\tO\n",
            "ఈ\tO\n",
            "జాతులు\tO\n",
            "చాలా\tO\n",
            "విటమిన్లు\tO\n",
            "మరియు\tO\n",
            "ట్రేస్\tO\n",
            "ఎలిమెంట్స్\tO\n",
            "చాలా\tO\n",
            "గొప్ప\tO\n",
            "ఉంది\tO\n",
            ",\tO\n",
            "ప్రోటీన్\tO\n",
            "చాలా\tO\n",
            "కలిగి\tO\n",
            "మరియు\tO\n",
            "మొత్తం\tO\n",
            "చాలా\tO\n",
            "విలువైన\tO\n",
            "కూర్పు\tO\n",
            "ఉంది\tO\n",
            ".\tO\n",
            "జి.ఎస్‌.టి.\tB-ORG\n",
            "కౌన్సిల్‌\tO\n",
            "సమావేశం\tI-ORG\n",
            "తరువాత\tO\n",
            "జైట్లీ\tO\n",
            "ప్రకటించిన\tO\n",
            "ప్యాకేజీలో\tO\n",
            "చిన్న\tO\n",
            ",\tO\n",
            "మధ్యతరహా\tO\n",
            "పరిశ్రమాధిపతులకు\tO\n",
            ",\tO\n",
            "చేయూతనందించే\tO\n",
            "పథకంగా\tO\n",
            "ఉందని\tO\n",
            "ప్రశంసించారు\tO\n",
            ".\tO\n",
            "వాస్తవానికి\tO\n",
            "ఈ\tO\n",
            "పారిశ్రామిక\tO\n",
            "వర్గం\tO\n",
            "యొక్క\tO\n",
            "అవస్థలను\tO\n",
            "అవగాహన\tO\n",
            "చేసుకోకుండా\tO\n",
            ",\tO\n",
            "చేసుకుందామనే\tO\n",
            "తపన\tO\n",
            "కూడా\tO\n",
            "లేకుండా\tO\n",
            "ఈ\tO\n",
            "విధానాలను\tO\n",
            "రూపొం\tO\n",
            "దించారు\tO\n",
            ".\tO\n",
            "లేదా\tO\n",
            "కావాలనే\tO\n",
            "తాము\tO\n",
            "అమలు\tO\n",
            "చెయ్యాలనుకున్న\tO\n",
            "విధానాన్నే\tO\n",
            "కొనసాగించి\tO\n",
            "వీరిని\tO\n",
            "దెబ్బతీయాలని\tO\n",
            "నిర్ణయించుకున్నారు\tO\n",
            ".\tO\n",
            "తూతూ\tO\n",
            "మంత్రంగా\tO\n",
            "రాయితీలు\tO\n",
            "ప్రకటించారనటానికి\tO\n",
            "రెండు\tO\n",
            "ఉదాహరణలు\tO\n",
            ".\tO\n",
            "మొదటిది\tO\n",
            "కాంపౌండింగ్‌\tO\n",
            "స్కీము\tO\n",
            "యొక్క\tO\n",
            "పరిధిని\tO\n",
            "డెబ్బై\tO\n",
            "ఐదు\tO\n",
            "లక్షల\tO\n",
            "నుంచి\tO\n",
            "కోటి\tO\n",
            "రూపాయలకు\tO\n",
            "పెంచడం\tO\n",
            ".\tO\n",
            "చిన్న\tO\n",
            "చిన్న\tO\n",
            "పరిశ్రమలు\tO\n",
            "ఏవైతే\tO\n",
            "ఈ\tO\n",
            "పరిధి\tO\n",
            "టర్నోవర్‌లో\tO\n",
            "ఉన్నాయో\tO\n",
            ",\tO\n",
            "వారు\tO\n",
            "చేసే\tO\n",
            "ఉత్పత్తిని\tO\n",
            "బట్టి\tO\n",
            "నిర్ణయించ\tO\n",
            "బడిన\tO\n",
            "పన్నురేటు\tO\n",
            "ప్రకారం\tO\n",
            "ఒకటి\tO\n",
            "నుంచి\tO\n",
            "ఐదు\tO\n",
            "శాతం\tO\n",
            "వరకు\tO\n",
            "కట్టడం\tO\n",
            ".\tO\n",
            "వ్యాపారులకు\tO\n",
            "ఒక\tO\n",
            "శాతం\tO\n",
            ",\tO\n",
            "తయారీదారులకు\tO\n",
            "2\tO\n",
            "శాతం\tO\n",
            ",\tO\n",
            "సరఫరా\tO\n",
            "దారులకు\tO\n",
            "రెండు\tO\n",
            "శాతం\tO\n",
            ",\tO\n",
            "రెస్టారెంట్లకు\tO\n",
            "ఐదు\tO\n",
            "శాతం\tO\n",
            ".\tO\n",
            "దేశంలో\tO\n",
            "ఉన్న\tO\n",
            "80-90\tO\n",
            "లక్షల\tO\n",
            "మంది\tO\n",
            "పన్ను\tO\n",
            "చెల్లించే\tO\n",
            "వారిలో\tO\n",
            "10-50\tO\n",
            "లక్షల\tO\n",
            "పారిశ్రా\tO\n",
            "మిక\tO\n",
            "యూనిట్లు\tO\n",
            "అంటే\tO\n",
            ",\tO\n",
            "దాదాపు\tO\n",
            "17\tO\n",
            "శాతం\tO\n",
            "ఈ\tO\n",
            "స్కీములోకి\tO\n",
            "రావడానికి\tO\n",
            "ముందుకొచ్చారు\tO\n",
            ".\tO\n",
            "ఆ\tO\n",
            "పరిధి\tO\n",
            "పెరగటం\tO\n",
            "వలన\tO\n",
            "జి.ఎస్‌.టి.\tO\n",
            "పన్ను\tO\n",
            "చెల్లింపుదారులలో\tO\n",
            "ఐదింట\tO\n",
            "ఒకవంతు\tO\n",
            "మంది\tO\n",
            "ఈ\tO\n",
            "స్కీములోకి\tO\n",
            "వచ్చారన్నమాట\tO\n",
            ".\tO\n",
            "దిల్‌రాజు\tB-PER\n",
            "నైజాం\tI-PER\n",
            "రైట్స్‌ను\tO\n",
            "తన\tO\n",
            "వద్ద\tO\n",
            "ఉంచుకుని\tO\n",
            "మిగిలి\tO\n",
            "అన్ని\tO\n",
            "ఏరియాలను\tO\n",
            "అమ్మేసే\tO\n",
            "యోచనలో\tO\n",
            "ఉన్నాడు\tO\n",
            ".\tO\n",
            "మరోవైపు\tO\n",
            "…\tO\n",
            "హైదరాబాద్\tB-LOC\n",
            "లో\tO\n",
            "అంబేద్కర్\tB-LOC\n",
            "మహావాదుల\tI-LOC\n",
            "సభకు\tI-LOC\n",
            "జిల్లాలనుంచి\tO\n",
            "బయల్దేరిన\tO\n",
            "వారిని\tO\n",
            "పోలీసులు\tO\n",
            "అడ్డుకున్నారు\tO\n",
            ".\tO\n",
            "ఈ\tO\n",
            "ఖర్చులు\tO\n",
            "వ్యాపార\tO\n",
            "వ్యయంగా\tO\n",
            "పరిగణించబడుతున్నాయి\tO\n",
            ",\tO\n",
            "అందువల్ల\tO\n",
            "అధిక\tO\n",
            "వ్యయం\tO\n",
            "లేదా\tO\n",
            "ఆధారం\tO\n",
            ",\tO\n",
            "మీరు\tO\n",
            "ఎక్కువగా\tO\n",
            "వ్యయంతో\tO\n",
            "తీసివేయవచ్చు\tO\n",
            "-\tO\n",
            "కానీ\tO\n",
            "ఇది\tO\n",
            "ఆస్తిపై\tO\n",
            "మీ\tO\n",
            "ఆధారంను\tO\n",
            "తగ్గిస్తుంది\tO\n",
            ".\tO\n",
            "మొదటి\tO\n",
            "దశలోనే\tO\n",
            "గుర్తిస్తే\tO\n",
            "వైద్యం\tO\n",
            "నయం\tO\n",
            ":\tO\n",
            "కిడ్నీ\tO\n",
            "వ్యాధిని\tO\n",
            "మొదటి\tO\n",
            "దశలోనే\tO\n",
            "గుర్తిస్తే\tO\n",
            "కొంత\tO\n",
            "మేరకు\tO\n",
            "నయం\tO\n",
            "చేసుకోవచ్చు\tO\n",
            ".\tO\n",
            "2007లో\tO\n",
            "జయలలిత\tB-PER\n",
            "మరణం\tO\n",
            "గురించి\tO\n",
            "వరుణ్\tB-PER\n",
            "ఎలా\tO\n",
            "ప్రస్తావిస్తాడు\tO\n",
            "అని\tO\n",
            "మురగదాస్\tO\n",
            "ప్రశ్నించారు\tO\n",
            ".\tO\n",
            "అనంతరం\tO\n",
            "…\tO\n",
            "నారాయణ్‌\tO\n",
            " పేట్‌\tO\n",
            "జిల్లా\tO\n",
            "కలెక్టర్ \tO\n",
            "వెంకట్రావు\tB-PER\n",
            ",\tO\n",
            "హైదరాబాద్‌ \tB-LOC\n",
            "జాయింట్ \tI-ORG\n",
            "కలెక్టర్‌\tO\n",
            "రవి\tB-PER\n",
            "గుగులోత్‌\tI-PER\n",
            ",\tO\n",
            "హైదరాబాద్‌ \tB-LOC\n",
            "డీఆర్‌\tO\n",
            "వో\tB-PER\n",
            "భూపాల్\tI-PER\n",
            "రెడ్డికి\tI-PER\n",
            "…\tO\n",
            "హరిత\tO\n",
            "సవాల్\tO\n",
            "విసిరారు\tO\n",
            ".\tO\n",
            "మెగా\tO\n",
            "పవర్\tO\n",
            "స్టార్\tO\n",
            "రామ్\tB-PER\n",
            "చరణ్\tI-PER\n",
            ",\tO\n",
            "ఊరమాస్\tO\n",
            "డైరెక్టర్\tO\n",
            "బోయపాటి\tB-PER\n",
            "శ్రీను\tI-PER\n",
            "కాంబినేషన్‌లో\tO\n",
            ",\tO\n",
            "ఫ్యామిలీ\tO\n",
            ",\tO\n",
            "లవ్\tO\n",
            "అండ్\tO\n",
            "యాక్షన్\tO\n",
            "ఎంటర్‌టైనర్‌గా\tO\n",
            "రూపొందిన\tO\n",
            "వినయ\tO\n",
            "విధేయ\tO\n",
            "రామ\tO\n",
            ",\tO\n",
            "జనవరి\tO\n",
            "11న\tO\n",
            "వరల్డ్\tO\n",
            "వైడ్\tO\n",
            "గ్రాండ్\tO\n",
            "రిలీజ్‌కి\tO\n",
            "రెఢీ\tO\n",
            "అయిపోయింది\tO\n",
            ".\tO\n",
            "డి.\tO\n",
            "వి.\tO\n",
            "వి.\tO\n",
            "దానయ్య\tO\n",
            "నిర్మించగా\tB-PER\n",
            ",\tI-PER\n",
            "కైరా\tI-PER\n",
            "అద్వాణీ\tI-PER\n",
            "హీరోయిన్‌గా\tO\n",
            "నటించింది\tO\n",
            ".\tB-PER\n",
            "భూమి\tO\n",
            "యొక్క\tO\n",
            "ప్రధాన\tO\n",
            "అంశంపై\tO\n",
            "కృష్ణ\tO\n",
            "పదార్థాన్ని\tO\n",
            "నాశనం\tO\n",
            "చేసే\tO\n",
            "ఉష్ణాన్ని\tO\n",
            "అగ్నిపర్వత\tO\n",
            "విస్పోటనములు\tO\n",
            ",\tO\n",
            "పర్వత\tO\n",
            "భవనం\tO\n",
            ",\tO\n",
            "మాగ్నెటిక్\tO\n",
            "క్షేత్ర\tO\n",
            "విపర్యయాలు\tO\n",
            "మరియు\tO\n",
            "సముద్ర\tO\n",
            "మట్టం\tO\n",
            "లో\tO\n",
            "మార్పులు\tO\n",
            "వంటి\tO\n",
            "కార్యక్రమాలను\tO\n",
            "ప్రేరేపించగలవు\tO\n",
            ".\tO\n",
            "లేదా\tO\n",
            "ప్రాజెక్ట్\tO\n",
            "వర్క్స్\tO\n",
            "కంప్లీట్\tO\n",
            ".\tO\n",
            ".\tO\n",
            ".\tO\n",
            "క్షణికావేశం\tO\n",
            ":\tO\n",
            "కాలేజీ\tO\n",
            "బిల్డింగ్\tO\n",
            "పై\tO\n",
            "నుంచి\tO\n",
            "దూకబోయిన\tO\n",
            "యువతి\tO\n",
            ".\tO\n",
            "15\tO\n",
            "నిమిషాలు\tO\n",
            "ఒవెన్\tO\n",
            "లో\tO\n",
            "తడకగల\tO\n",
            "జున్ను\tO\n",
            "మరియు\tO\n",
            "రొట్టెలుకాల్చు\tO\n",
            "తో\tO\n",
            "చల్లుకోవటానికి\tO\n",
            ".\tO\n",
            "ఓ\tO\n",
            "మృతదేహానికి\tO\n",
            "తల\tO\n",
            "వెనుక\tO\n",
            "భాగంలో\tO\n",
            ",\tO\n",
            "మరోదానికి \tO\n",
            "కన్ను\tO\n",
            ",\tO\n",
            "నుదురు\tO\n",
            "ప్రాంతాల్లో\tO\n",
            "గాయాలను\tO\n",
            "గుర్తించారు\tO\n",
            ".\tO\n",
            "సెర్చ్\tO\n",
            "చేయడానికి\tO\n",
            "మీరు\tO\n",
            "వాయిస్\tO\n",
            "కమాండ్\tO\n",
            "ఇవ్వడం\tO\n",
            "లేదా\tO\n",
            "స్క్రైబుల్\tO\n",
            "ఇన్పుట్\tO\n",
            "పద్ధతిని\tO\n",
            "కూడా\tO\n",
            "ఉపయోగించవచ్చు\tO\n",
            ".\tO\n",
            "తరువాతి\tO\n",
            "రెండు\tO\n",
            "సంవత్సరాలలో\tO\n",
            ",\tO\n",
            "జాన్సన్\tB-PER\n",
            "తన\tO\n",
            "అల్మా\tO\n",
            "మేటర్లోని\tO\n",
            "ఇంగ్లీష్\tO\n",
            ",\tO\n",
            "చరిత్ర\tO\n",
            "మరియు\tO\n",
            "ఆర్థిక\tO\n",
            "శాస్త్రాన్ని\tO\n",
            "బోధించాడు\tO\n",
            ",\tO\n",
            "చికాగో\tO\n",
            "విశ్వవిద్యాలయం\tB-ORG\n",
            "నుండి\tO\n",
            "రెండవ\tO\n",
            "బ్యాచులర్\tO\n",
            "డిగ్రీ\tO\n",
            "పొందే\tO\n",
            "ముందు\tO\n",
            ".\tO\n",
            "మాట్లాడటం\tO\n",
            "మొదలెట్టాకా\tO\n",
            "ఏ\tO\n",
            "పక్కనుంచైనా\tO\n",
            "చప్పట్ల\tO\n",
            "శబ్దం\tO\n",
            "వినిపించిందనుకోండి\tO\n",
            "ఇక\tO\n",
            "వాళ్ల\tO\n",
            "ప్రసంగం\tO\n",
            "అనబడే\tO\n",
            "వాగుడు.\tO\n",
            ".\tO\n",
            ".\tO\n",
            "ఈసీ\tO\n",
            "నోటీసుకు\tO\n",
            "స్పందించిన\tO\n",
            "యోగి\tB-PER\n",
            "ఆదిత్యనాథ్\tI-PER\n",
            "అయితే\tO\n",
            ",\tO\n",
            "పంప్\tO\n",
            "ద్వారా\tO\n",
            "ఉత్పత్తి\tO\n",
            "గాలి\tO\n",
            "గతి,\tO\n",
            "ఏకరీతి\tO\n",
            "వార్నిష్\tO\n",
            "లేదా\tO\n",
            "పెయింట్\tO\n",
            "డౌన్\tO\n",
            "వేయడానికి\tO\n",
            "అనుమతించము\tO\n",
            ".\tO\n",
            "సుప్రీం\tB-ORG\n",
            "కోర్టులో\tO\n",
            "పిల్\tO\n",
            "వేస్తాం\tO\n",
            ",\tO\n",
            "ఇందులో\tO\n",
            "మా\tO\n",
            "అసోసియేషన్\tO\n",
            ",\tO\n",
            "జూనియర్\tO\n",
            "ఆర్టిస్టులు\tO\n",
            ",\tO\n",
            "పవన్\tB-PER\n",
            "కళ్యాణ్\tI-PER\n",
            "అభిమానులు\tO\n",
            "ఇలా\tO\n",
            "ఎవరు\tO\n",
            "కామెంట్\tO\n",
            "చేసినా\tO\n",
            "వారిపై\tO\n",
            "క్రిమినల్\tO\n",
            "కేసులు\tO\n",
            ",\tO\n",
            "సైబర్\tO\n",
            "యాక్ట్\tO\n",
            "కింద\tO\n",
            "కేసులు\tO\n",
            "పెడతాం\tO\n",
            "’\tO\n",
            "అని\tO\n",
            "హెచ్చరించారు\tO\n",
            ".\tO\n",
            "అది\tO\n",
            "చెడు\tO\n",
            "వాసన\tO\n",
            "వచ్చింది\tO\n",
            "''\tO\n",
            "అని\tO\n",
            "ఆ\tO\n",
            "పూజా\tO\n",
            "కార్యక్రమానికి\tO\n",
            "హాజరైన\tO\n",
            "ఒక\tO\n",
            "వ్యక్తి\tO\n",
            "మీడియాకు\tO\n",
            "తెలిపారు\tO\n",
            ".\tO\n",
            "ఆతర్వాత\tO\n",
            "అన్ని\tO\n",
            "డైలాగులు\tO\n",
            "నా\tO\n",
            "కన్నా\tO\n",
            "పవర్\tO\n",
            "ఫుల్\tO\n",
            "గా\tO\n",
            "చెప్పేసింది\tO\n",
            "అని\tO\n",
            "కోడి\tO\n",
            "రామకృష్ణ\tB-PER\n",
            "అన్నారు\tO\n",
            ".\tO\n",
            "తమ\tO\n",
            "40\tO\n",
            "సంవత్సరాల\tO\n",
            "చిరకాల\tO\n",
            "స్వప్నం\tO\n",
            "సాకారమవుతున్నందుకు\tO\n",
            "పెన్\tO\n",
            "గంగ\tO\n",
            "పరివాహక\tO\n",
            "రైతాంగం\tO\n",
            "ఆనందం\tO\n",
            "వ్యక్తం\tO\n",
            "చేస్తోంది\tO\n",
            ".\tO\n"
          ]
        }
      ],
      "source": [
        "label_id={ \"LABEL_0\":'O', \"LABEL_1\": \"B-PER\", \"LABEL_2\": \"I-PER\", \"LABEL_3\": \"B-ORG\", \"LABEL_4\":\"I-ORG\", \"LABEL_5\":\"B-LOC\", \"LABEL_6\":\"I-LOC\"}\n",
        "for sentence in sentences:\n",
        "  predicted_labels = get_predictions(sentence=sentence,\n",
        "                                   tokenizer=tokenizer,\n",
        "                                   model=model\n",
        "                                   )\n",
        "\n",
        "  words = sentence.split(' ')\n",
        "  # Ensure the length of predicted labels matches the number of words\n",
        "  if len(predicted_labels) > len(words):\n",
        "    predicted_labels = predicted_labels[:len(words)]\n",
        "\n",
        "  for i in range(len(words)):\n",
        "    print( sentence.split(' ')[index] + '\\t' + label_id[predicted_labels[index]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-12T20:50:07.838093Z",
          "iopub.status.busy": "2024-03-12T20:50:07.837733Z",
          "iopub.status.idle": "2024-03-12T20:50:10.643186Z",
          "shell.execute_reply": "2024-03-12T20:50:10.642246Z",
          "shell.execute_reply.started": "2024-03-12T20:50:07.838068Z"
        },
        "id": "HGIqHcQg6eJN",
        "outputId": "565b4442-e99a-4103-ee81-5b8567a52025"
      },
      "outputs": [],
      "source": [
        "# Open a text file in write mode\n",
        "with open('predicted_labels_bert.txt', 'w') as file:\n",
        "  for sentence in sentences:\n",
        "    predicted_labels = get_predictions(sentence=sentence,\n",
        "                                      tokenizer=tokenizer,\n",
        "                                      model=model)\n",
        "    #print(len(sentence.split(' ')),len(predicted_labels))\n",
        "\n",
        "    for index in range(len(sentence.split(' '))):\n",
        "      if (sentence.split(' ')[index]!=\" \"):\n",
        "        file.write(sentence.split(' ')[index] + '\\t' +  label_id[predicted_labels[index]] + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-12T20:51:13.405380Z",
          "iopub.status.busy": "2024-03-12T20:51:13.404266Z",
          "iopub.status.idle": "2024-03-12T20:51:13.475773Z",
          "shell.execute_reply": "2024-03-12T20:51:13.474675Z",
          "shell.execute_reply.started": "2024-03-12T20:51:13.405332Z"
        },
        "id": "NoIWy0fGd7Mb"
      },
      "outputs": [],
      "source": [
        "def read_and_tokenize_file(file_path, tokenizer):\n",
        "    data = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                line_data = eval(line)  # Convert the string representation of the dictionary to a dictionary\n",
        "                tokens = line_data[\"tokens\"]\n",
        "                ner_tags = line_data[\"ner_tags\"]\n",
        "                line_dict = {\"tokens\": tokens, \"ner_tags\": ner_tags}\n",
        "                data.append(line_dict)\n",
        "    return data\n",
        "\n",
        "\n",
        "# Specify the path to the text file\n",
        "file_path = \"colab_maual.txt\"\n",
        "\n",
        "# Read and tokenize the file\n",
        "tokenized_data = read_and_tokenize_file(file_path, tokenizer)\n",
        "ground_truth_tokens=[]\n",
        "ground_truth_tokenized_labels=[]\n",
        "# Print the tokenized data\n",
        "c=0\n",
        "for line_data in tokenized_data:\n",
        "  # c+=1\n",
        "  # if(c==4):\n",
        "  #   for i in range(15):\n",
        "  #     print(line_data[\"tokens\"][i],line_data[\"ner_tags\"][i])\n",
        "  if(\",\" in line_data[\"ner_tags\"]):\n",
        "    for i in range(len(line_data[\"ner_tags\"])):\n",
        "      print(line_data[\"tokens\"][i],line_data[\"ner_tags\"][i])\n",
        "      if(line_data[\"ner_tags\"][i]==\"OO\"): print(\"culprit \",i)\n",
        "  ground_truth_tokens.extend(line_data[\"tokens\"])\n",
        "  ground_truth_tokenized_labels.extend(line_data[\"ner_tags\"])\n",
        "  #print(len(line_data[\"tokens\"]),len(line_data[\"ner_tags\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-12T20:51:23.910582Z",
          "iopub.status.busy": "2024-03-12T20:51:23.909714Z",
          "iopub.status.idle": "2024-03-12T20:51:26.467253Z",
          "shell.execute_reply": "2024-03-12T20:51:26.464527Z",
          "shell.execute_reply.started": "2024-03-12T20:51:23.910549Z"
        },
        "id": "AAaaYZ5G-dOf",
        "outputId": "0a701e79-7844-4898-e0d4-252395389b88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22 22\n",
            "12 12\n",
            "12 12\n",
            "15 15\n",
            "26 26\n",
            "144 144\n",
            "13 13\n",
            "13 13\n",
            "24 24\n",
            "16 16\n",
            "11 11\n",
            "24 24\n",
            "43 43\n",
            "27 27\n",
            "16 16\n",
            "11 11\n",
            "14 14\n",
            "13 13\n",
            "25 25\n",
            "19 19\n",
            "16 16\n",
            "32 32\n",
            "15 15\n",
            "14 14\n",
            "14 14\n",
            "\n"
          ]
        }
      ],
      "source": [
        "label_id={ \"LABEL_0\":'O', \"LABEL_1\": \"B-PER\", \"LABEL_2\": \"I-PER\", \"LABEL_3\": \"B-ORG\", \"LABEL_4\":\"I-ORG\", \"LABEL_5\":\"B-LOC\", \"LABEL_6\":\"I-LOC\"}\n",
        "import torch\n",
        "predicted_labels_global=[]\n",
        "predicted_tokens=[]\n",
        "for sentence in sentences:\n",
        "  predicted_labels = get_predictions(sentence=sentence,\n",
        "                                    tokenizer=tokenizer,\n",
        "                                    model=model)\n",
        "\n",
        "  words = sentence.split(' ')\n",
        "  # Ensure the length of predicted labels matches the number of words\n",
        "  if len(predicted_labels) > len(words):\n",
        "    predicted_labels = predicted_labels[:len(words)]\n",
        "  print(len(words),len(predicted_labels))\n",
        "  for i in range(len(words)):\n",
        "    #print(words[i], predicted_labels[i])\n",
        "    predicted_tokens.append(words[i])\n",
        "    predicted_labels_global.append( label_id[predicted_labels[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjtDZ2AJiAjk",
        "outputId": "6fc4bd62-0aae-44e7-a70c-8f75dd251216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-LOC', 'I-ORG', 'O', 'B-PER', 'I-PER', 'O', 'B-LOC', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "print(predicted_labels_global)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-5Rh5VVibKR",
        "outputId": "5e40aa10-c149-4220-c85c-4cefc7c44157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "591 591\n"
          ]
        }
      ],
      "source": [
        "print(len(predicted_labels_global),len(ground_truth_tokenized_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGuCdRWkd4I3",
        "outputId": "2c7ac299-a649-4b0c-b338-9bc760890f50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "591 591\n"
          ]
        }
      ],
      "source": [
        "print(len(ground_truth_tokens),len(predicted_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-12T20:51:46.548818Z",
          "iopub.status.busy": "2024-03-12T20:51:46.548440Z",
          "iopub.status.idle": "2024-03-12T20:51:46.557015Z",
          "shell.execute_reply": "2024-03-12T20:51:46.555570Z",
          "shell.execute_reply.started": "2024-03-12T20:51:46.548789Z"
        },
        "id": "KGCMb_uN--0d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score,classification_report\n",
        "def calculate_metrics(predicted_labels, ground_truth_labels):\n",
        "    precision = precision_score(ground_truth_labels, predicted_labels, average='macro')\n",
        "    recall = recall_score(ground_truth_labels, predicted_labels, average='macro')\n",
        "    f1_sco = f1_score(ground_truth_labels, predicted_labels, average='macro')\n",
        "    #report=classification_report(ground_truth_labels, predicted_labels)\n",
        "    return precision, recall, f1_sco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-12T20:51:52.761621Z",
          "iopub.status.busy": "2024-03-12T20:51:52.761218Z",
          "iopub.status.idle": "2024-03-12T20:51:52.807674Z",
          "shell.execute_reply": "2024-03-12T20:51:52.806405Z",
          "shell.execute_reply.started": "2024-03-12T20:51:52.761573Z"
        },
        "id": "X0ZNFgKB--5f",
        "outputId": "542356b1-ed27-404a-c739-1df670d94250"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "p,r,f1=calculate_metrics(predicted_labels_global,ground_truth_tokenized_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-12T20:51:55.637194Z",
          "iopub.status.busy": "2024-03-12T20:51:55.636820Z",
          "iopub.status.idle": "2024-03-12T20:51:55.645767Z",
          "shell.execute_reply": "2024-03-12T20:51:55.644677Z",
          "shell.execute_reply.started": "2024-03-12T20:51:55.637154Z"
        },
        "id": "M7bOnKol--9j",
        "outputId": "4642477b-93dc-433b-c49c-c28f7b074d00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision:  0.3923867974500886 \n",
            " Recall:  0.3443784924688974 \n",
            " F1-Score:  0.3629307783719548\n"
          ]
        }
      ],
      "source": [
        "print(\"Precision: \",p,\"\\n\",\"Recall: \",r,\"\\n\",\"F1-Score: \",f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaDTxDLhT6Ni",
        "outputId": "b9a5484f-d872-440f-bc6f-2a7a12a472b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.60      0.50      0.55         6\n",
            "      B-MISC       0.00      0.00      0.00        27\n",
            "       B-ORG       0.67      0.40      0.50         5\n",
            "       B-PER       0.73      0.58      0.65        19\n",
            "       I-LOC       0.00      0.00      0.00         1\n",
            "      I-MISC       0.00      0.00      0.00        15\n",
            "       I-ORG       0.00      0.00      0.00         4\n",
            "       I-PER       0.64      0.64      0.64        11\n",
            "           O       0.90      0.98      0.94       503\n",
            "\n",
            "    accuracy                           0.88       591\n",
            "   macro avg       0.39      0.34      0.36       591\n",
            "weighted avg       0.81      0.88      0.84       591\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "report=classification_report(ground_truth_tokenized_labels,predicted_labels_global)\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4587482,
          "sourceId": 7828167,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30665,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
